# Logstash实现DB2数据库向Postgres数据库的表数据转储

## Logstash配置
```
input {
  jdbc {
    jdbc_connection_string => "jdbc:db2://192.168.73.110:50000/testdb"
    jdbc_user => "db2inst1"
    jdbc_password => "db2inst1"
    jdbc_driver_class => "com.ibm.db2.jcc.DB2Driver"
    jdbc_driver_library => "/opt/logstash-6.0.0/vendor/jar/jdbc/db2jcc.jar"
    jdbc_paging_enabled => "true"
    jdbc_page_size => "50000"
    statement => "select RES_ID, RULE_ID, CREATE_TIME, LAST_TIME, STATUS, IS_PUSHED, VALUE FROM ITM_ALARM_SNAP where last_time > ''||:sql_last_value order by last_time"
    schedule => "* * * * *"
    type => "jdbc_alarm"
    record_last_run => true
    use_column_value => true
    tracking_column => last_time
    last_run_metadata_path => "/opt/logstash-6.0.0/jdbc_metadata/itm_alarm_snap.conf"
    clean_run => false
    
  }
}
filter {
  json {
    source => "message"
  }
}
output {
 stdout {
    codec => rubydebug
  }

  jdbc {
    connection_string => "jdbc:postgresql://192.168.73.110:5432/kong?user=kong&password=123456a?"
    statement => ["insert into ITM_ALARM_SNAP(res_id, rule_id, create_time, last_time, status, value, is_pushed) values (?, ?, ?, ?, ?, ?, ?)", "%{[res_id]}", "%{[rule_id]}", "%{[create_time]}", "%{[last_time]}", "%{[status]}", "%{[value]}", "%{[is_pushed]}"]
  }
}
```
input:<br>
  jdbc:<br>
    jdbc_connection_string:  数据库连接字符串<br>
    jdbc_driver_class：数据库连接驱动类<br>
    jdbc_driver_library：驱动jar包路径<br>
    statement：数据查询SQL<br>
    statement_filepath: 数据查询SQL文件路径，与statement二选一<br>
    schedule：定时配置，cron表达式，例如："* * * * *"表示每分钟执行一次<br>
    record_last_run：是否记录上一次执行结果<br>
    use_column_value：是否使用数据库表的字段跟踪执行结果<br>
    tracking_column：跟踪字段，与record_last_run、use_column_value结合使用<br>
    last_run_metadata_path：上一次执行保存的跟踪字段的值的路径，用于增量更新数据，与tracking_column结合使用<br>
当有多个数据库input时，需要为每个数据库源配置jdbc，如下所示：
```
input {
  jdbc {
    jdbc_connection_string => "jdbc:db2://192.168.73.110:50000/testdb1"
    jdbc_user => "db2inst1"
    type => "jdbc_alarm1"
    ...
  }
  jdbc {
    jdbc_connection_string => "jdbc:db2://192.168.73.110:50000/testdb2"
    jdbc_user => "db2inst2"
    type => "jdbc_alarm2"
    ...
  }
}
filter {
  json {
    source => "message"
  }
}
output {
  if[type] == "jdbc_alarm1"{
    jdbc {
      connection_string => "jdbc:postgresql://192.168.73.110:5432/kong?user=kong&password=123456a?"
      statement => ["insert into ITM_ALARM_SNAP(res_id, rule_id, create_time, last_time, status, value, is_pushed) values (?, ?, ?, ?, ?, ?, ?)", "%{[res_id]}", "%{[rule_id]}", "%{[create_time]}", "%{[last_time]}", "%{[status]}", "%{[value]}", "%{[is_pushed]}"]
    }
  }
  if[type] == "jdbc_alarm2"{
    jdbc {
      connection_string => "jdbc:postgresql://192.168.73.110:5432/kong?user=kong&password=123456a?"
      statement => ["insert into ITM_ALARM_SNAP(res_id, rule_id, create_time, last_time, status, value, is_pushed) values (?, ?, ?, ?, ?, ?, ?)", "%{[res_id]}", "%{[rule_id]}", "%{[create_time]}", "%{[last_time]}", "%{[status]}", "%{[value]}", "%{[is_pushed]}"]
    }
  }
}
```

## 启动logstash
/opt/logstash-6.0.0/bin:
```
./logstash -f ../conf/jdbcinout.conf -r true
```
-f: 指定数据转储配置文件
-r: 是否动态加载配置文件
